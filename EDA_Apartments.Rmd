---
title: "Housing Market Cleaning - Apartments"
output: html_document
css: article.css
---

```{r setup_general, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = "#>", collapse = TRUE, message = FALSE)
```

```{r setup_libraries}

library(dplyr)
library(purrr)
library(tidyr)
library(stringr)
library(kableExtra)
```

In this article I will try to disentangle and clean the data taken from the [imobiliare.ro](imobiliare.ro) website. The data is messy and I would like to use this document to record all I have done in order to clean it so it can be discussed later. Before all that, I would like to explain a little bit how I acquired the data and what problems I have encountered in doing so. This might help clarify some of the problems and inconsistencies within the data.

## The data

The data comes from the website [imobiliare.ro](imobiliare.ro) and I used a web scrapping algorithm to get the data. The algorithm can be found at the following [GitHub repo](https://github.com/VladAluas/Housing_Market). Because it is easier to keep the data and the code separate and roll something back should it be the case, I have decided to keep the data in a separate [repo](https://github.com/VladAluas/Housing_Market_Datasets). Here you can see all the datasets I have scrapped from the website.

As you might have noticed the data was downloaded once a week, specifically on Tuesday. There is no particular reason for that, I just wanted to download the data once a week and the first download was on Tuesday, so I continued with that.

The last data download was on the 29^th^ of September. The website changed it's structure shortly after that and I will need to adjust the the web scrapping algorithm to do so. I did not have time to deal with it at the moment. When I will be able to tackle that I will add more data.

I will expose the code I have used to clean the data so it can be reproduced or discussed at a later date.

## Data Cleaning Logic

#### Data ingestion

```{r data_ingestion}
df_list <- map(list.files(paste(getwd(), "_Datasets", sep = ""), pattern = "Apartamente", full.names = TRUE), read.csv)
```

#### Integrating all the datasets into one

There are some problems with the data that I would like to address and list the steps I consider as necessary to clean the data.

The first thing to consider is the fact that the web scrapping script suffered some changes over time and the columns differ slightly across the files. Most problematic are the following columns:

-   **Construction Year**: At first I let the column name in Romanian and that resulted in some problems later due to my OS not recognizing the characters so I decided to change the name to English

-   **Parking Spots**: This column at first appears as **Parking Places**. I cannot recall why the change in name occurred, however, we will need to correct this as well.

-   **Website**: In the latest datasets I've added a column containing the web page in which one can see the offer. I will eliminate it since it does not help in our analysis.

I will start with the **Website** column.

```{r eliminate_Website}
df_list <- map(df_list, function(x) if ("Website" %in% names(x)) x <- x %>% select(-Website) else x)
```

The next step is to make sure the columns have the same names in all datasets. I will take them from the last dataset in the list.

```{r standardize_columns}
# Names of the last data frame
col_names <- names(df_list[[length(df_list)]])

# Replacing the "." in the names with a "_"
col_names <- col_names %>% str_replace_all("\\.", "_")

# Changing Names
df_list <- map(df_list, function(x) set_names(x, col_names))
```

Now the datasets are standardized so we can append them in one data frame.

```{r flatten_the_list}
df <- map_df(df_list, rbind)
```

Let's take a look at the data.

```{r data_head , echo = FALSE}
df %>%
  head(10) %>%
  mutate(Title = "Lorem Ipsum") %>%
  kable(format = "html") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), fixed_thead = T) %>%
  scroll_box(height = "400px")

rm(df_list, col_names)
```

We can also summarize the numerical data so we can get a better understanding of how the data looks like.

```{r int_data_summary}
df %>%
  select(where(is.numeric)) %>%
  summary() %>%
  kable(format = "html") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), fixed_thead = T) %>%
  scroll_box(height = "400px")
```

From the start we can see that there are some extreme values (*e.g.* 47 kitchens, 78 rooms, *etc*) and missing values, some of which are easily resolvable (*e.g.* Garages, Parking_Spots), some of them are harder to do so (*e.g.* Price, Latitude, Longitude) and some are in between.

Let's start with the easy part and that would be filling in missing values and the transformations before proceeding to eliminate extreme values. We will also get the height regiment in a more useful format by getting the numeric value from the column.

So, for this part we will apply the following transformations:

-   **Floor:** Since all the values in this column are numerical, we can assume that most missing values from here come from the fact that the ground floor is marked as **P** in Romania and the software did not know how to convert to a number so I will replace them with **0**
-   **Bathrooms:** We will assume that all apartments have at least one bathroom so if a value is missing I will replace it with **1**.
-   **Kitchens:** We will use the same logic as above and if a value is missing I will replace it with **1**
-   **Rooms:** The same logic as above although since just one entry is affected by this we can replace it without much of an impact on the data
-   **Area:** This is a bit tricky since we cannot estimate an area just as easy. However, we can use a median value to estimate the area. The average will be affected by extreme values like **784 m^2^** usable area.
-   **Construction_Year:** We can safely use the same logic for the construction year as for area without impacting the data in a major way.
-   **Balconies, Garages, Parking_Spots:** This is quite straight forward, an apartment either has one of these facilities or it doesn't so we will replace the missing values with **0**
-   **Price and Geographical Coordinates:** They are harder to estimate since they are variables that we want to explain through the others. We will eliminate them from this data set, if they are missing, however, we can store them separately and we can try to predict them later on
-   **Height_Regiment:** We will extract the digits from the string and convert them to numeric then fill in the missing values with the median

```{r clean_test_datasets}
df_test <- df %>% filter(is.na(Price) | is.na(Latitude))

df <- df %>% 
        mutate(Height_Regiment = as.numeric(str_extract_all(Height_Regiment, "[0-9]+")),
               across(c("Bathrooms", "Kitchens", "Rooms"), ~ ifelse(is.na(.), 1, .)),
               across(c("Built_Area", "Usable_Area", "Total_Usable_Area", "Construction_Year", "Height_Regiment"), ~ ifelse(is.na(.), median(., na.rm = T), .)),
               across(c("Balconies", "Garages", "Parking_Spots", "Floor"), ~ ifelse(is.na(.), 0, .))) %>%
        filter(!is.na(Price), !is.na(Latitude))
```

Now that we have missing values figured out, let us try an deal with the extreme values. It is highly unlikely that an apartment will have 47 kitchens. Most apartments will have one or two at the most if they are either a penthouse or an apartment that was split for multiple families. The particular case mentioned above (47 kitchens) is an apartment building that is labelled as a single apartment. I assume that the owner wanted to let the customers know that he has multiple properties available.

These type of extreme values need to be filtered out since they will have a big impact on the analysis and the data will not tell us much about the average buyer (I will assume that the average buyer cannot buy an entire apartment building). In order to get a better idea about the housing market in Cluj I will try to focus on the apartments that are situated at less than three standard errors on the following attributes:

-   Number of Bathrooms
-   Number of Kitchens
-   Number of Rooms
-   Built_Area
-   Usable_Area
-   Total_Usable_Area
-   Parking_Spots
-   The Price

The rest of them don't have any extreme values that will impact the analysis.

```{r remove_outliers}
df <- df %>%
  filter(across(where(is.numeric), ~ between(scale(.), -3, 3)))
```

Let's check the numerical data one more time

```{r int_clean_data_summary}
df %>%
  select(where(is.numeric)) %>%
  summary() %>%
  kable(format = "html") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), fixed_thead = T) %>%
  scroll_box(height = "400px")
```

With the numerical data cleaned, it would be a good idea to deal with the character columns as well. We can start by trimming the special characters from the start and the end of the word.

That is easy to do and it can be done with one line of code. However, I will like to point out that these columns are not all the same, **Compartments** and **Comfort** have a very specific order and each data type has it's own place in the hierarchy so we will need to create some factors from the two columns and then we can fill in the missing values.

And for the missing values we will use the following logic:

-   **Compartments** and **Comfort** and correlated so we can deduce the value of one if we have the other
-   **Others** we will add the mode where the data is missing
-   **Compartments** has multiple ways of addressing the same type of apartment so we will transform the name.

```{r}
df <- df %>% 
  mutate(Compartments = ifelse(Compartments == "vagon", "nedecomandat", Compartments),
         Compartments = ifelse(Compartments == "circular", "semidecomandat", Compartments))
```


In the second part of the cleaning, we will see how they correlate to each other and then transform the columns.

```{r fill_na_comp_conf}
df %>%
  mutate(across(where(is.character), ~ str_trim(., "both")),
         Compartments = ifelse(Compartments == "vagon", "nedecomandat", Compartments),
         Compartments = ifelse(Compartments == "circular", "semidecomandat", Compartments),
         Compartments = ifelse(#Condition
                               is.na(Compartments),  
                               
                               # THEN
                               ifelse(Comfort == "lux" | Comfort == "1", "decomandat",
                               ifelse(Comfort == "2", "semidecomandat",
                               ifelse(Comfort == "3", "nedecomandat", NA))),
                              
                               # ELSE
                               Compartments),
         
         Comfort = ifelse(is.na(Comfort),
                          
                          ifelse(Compartments == "decomandat"    , "1",
                          ifelse(Compartments == "semidecomandat", "2",
                          ifelse(Compartments == "nedecomandat"  , "3", NA))),
                          
                          Comfort)) %>%
  filter(is.na(Comfort)) %>%
  View()
```

One last step with this columns, fill in the missing values for the two columns. There are `r df %>% filter(is.na(Comfort)) %>% summarise(n())` empty rows to fill in.

```{r factor_col}
comp_fct <- c("decomandat", "semidecomandat", "nedecomandat")
comf_fct <- c("lux", "1", "2", "3")


df <- df %>% 
  mutate(Compartments = factor(Compartments, levels = comp_fct),
         Comfort      = factor(Comfort,      levels = comf_fct))

rm(comp_fct, comf_fct)
```
```



```{r}
df %>% 
  group_by(Compartments) %>% 
  summarise(n())
```
```{r}
df %>% 
  group_by(Comfort) %>% 
  summarise(n())
```
```

